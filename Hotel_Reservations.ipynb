{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fawzy-AI-Explorer/Hotel_reservations-Classifications/blob/main/Hotel_Reservations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBU7CpTGTIdu"
      },
      "source": [
        "# **classification project**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rUvlF3lTh5c"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5X_mMBuMYFg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtI3dWrZTtOP"
      },
      "source": [
        "# Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZwY7VYqD1QH"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/Hotel Reservations.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XZnT8ZuT8O6"
      },
      "source": [
        "# Some informations about Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC68HFeHD64K"
      },
      "outputs": [],
      "source": [
        "#First 5 rows of our dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ocb4DJzU0lJ"
      },
      "outputs": [],
      "source": [
        "#Number of rows and columns\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRiiYy_TU4zx"
      },
      "source": [
        "dataset consists of 36275 rows and 19 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3L5DE4-D8UA"
      },
      "outputs": [],
      "source": [
        "# types of columns\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lrDPyd6UQc7"
      },
      "source": [
        "as we see we have :\n",
        "\n",
        "\n",
        "*   5 columns :\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ7csXohEXIh"
      },
      "outputs": [],
      "source": [
        "#Description of our dataset\n",
        "data.describe().T\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sWrIx9dEaQb"
      },
      "outputs": [],
      "source": [
        "#the skewness of our dataset\n",
        "\n",
        "data.skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDk1t8pzVU0_"
      },
      "source": [
        "\n",
        "\n",
        "*  Skewness tells us about the symmetry in a distribution.\n",
        "*  If Skewness is equal to zero , It is a symmetrical distribution.\n",
        "*   And If Skewness is less than or more than zero then it is a non-symmetrical distribution.\n",
        "*   If value is less than zero , distribution is left skewed and value is more than zero , distribution is right skewed.\n",
        "\n",
        "in the data :\n",
        "\n",
        "\n",
        "\n",
        "*   no_of_previous_cancellations\n",
        "*   no_of_previous_bookings_not_canceled\n",
        "*   required_car_parking_space\n",
        "*   no_of_children                                                             \n",
        "Are highly positively,right skewed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxbRMi_8Wvzw"
      },
      "outputs": [],
      "source": [
        "#Information of dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDKIf1I4W1LQ"
      },
      "source": [
        "The above information tells us\n",
        "\n",
        "\n",
        "*  Our dataset features consists of three datatypes\n",
        "\n",
        "\n",
        "1.   integer\n",
        "2.   float\n",
        "3.   object\n",
        "\n",
        "\n",
        "\n",
        "*   Of which total numerical features are 14\n",
        "*   And categorical features are 5.\n",
        "\n",
        "\n",
        "\n",
        "*  I see that the type of  all columns  is correct.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJAOxCcXYROe"
      },
      "outputs": [],
      "source": [
        "def is_non_numeric(x):\n",
        "    return not x.isnumeric()\n",
        "\n",
        "\n",
        "\n",
        "mask = data['Booking_ID'].apply(is_non_numeric)  # true --> if it is non num , false --> if it is num\n",
        "mask\n",
        "\n",
        "\n",
        "\n",
        "data_non_numeric = data[mask]\n",
        "data_non_numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_7WGYyzYIv7"
      },
      "outputs": [],
      "source": [
        "#Drop Id column as it is not required\n",
        "\n",
        "data.drop(columns=['Booking_ID'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbS5Gl8PYCOl"
      },
      "source": [
        "# Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTKacSydEfGo"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm8Wm56XEj4H"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb-MsNGeYiKL"
      },
      "source": [
        "*   We don not have missing values in dataset .\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFfiWK6FEnBs"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feiFMAqfY5ed"
      },
      "source": [
        "# Target Feature : booking_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT4qJRn8Y5Rf"
      },
      "outputs": [],
      "source": [
        "data['booking_status'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEnuwzOEZOxK"
      },
      "outputs": [],
      "source": [
        "data['booking_status'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDK-h-YKZS6l"
      },
      "outputs": [],
      "source": [
        "data['booking_status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmM37URkasZk"
      },
      "outputs": [],
      "source": [
        "# Countplot\n",
        "sns.countplot(data=data, x='booking_status')\n",
        "plt.title('Count of Each Category')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gANEMQRSZJqb"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Our target feature is a discrete variable with values ['Not_Canceled', 'Canceled']\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImS7bfdrbI7E"
      },
      "source": [
        "\n",
        "\n",
        "#   Booking Status with Other Features\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpiM_HrLbgI1"
      },
      "source": [
        "I will take numerical and categorical features and analyze the highly correlated features with our target feature.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbHQgi0CbkBu"
      },
      "source": [
        "**Numerical Analysis**                                                          \n",
        "There are two types of numerical features :\n",
        "\n",
        "*   Discrete and Continuous                                                     \n",
        "If there are discrete features in our dataset, we need to separate them and analyze as categorical variables.                                             \n",
        "\n",
        "Because if they are included in numerical analysis , we won't find any correlation between discrete features and target feature.    \n",
        "                                                                                \n",
        "\n",
        "\n",
        "\n",
        "                  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infkddxoeOD0"
      },
      "source": [
        "First step , I will separate discrete features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ787fmXeQlo"
      },
      "outputs": [],
      "source": [
        "discrete_features=[]\n",
        "for col in data.columns:\n",
        "    if data[col].dtype=='int64' and len(data[col].unique()) <=6:\n",
        "        discrete_features.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxaoBJtRenm1"
      },
      "outputs": [],
      "source": [
        "discrete_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX7CJVPeeuM3"
      },
      "source": [
        "As I see, there are incorrect columns , so I will add the discrete features manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koFgLU4reni1"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3zsA1OjenfZ"
      },
      "outputs": [],
      "source": [
        "for col in data.columns :\n",
        "  print (f\"{col} : {data[col].unique()} \\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iR_9Pwdffgm"
      },
      "source": [
        "I select these columns :\n",
        "*   arrival_year\n",
        "*   arrival_month\n",
        "*   arrival_date\n",
        "*   required_car_parking_space\n",
        "*   repeated_guest\n",
        "\n",
        "\n",
        "\n",
        "as I will create Date_Time list and add in it :\n",
        "*   arrival_year\n",
        "*   arrival_month\n",
        "*   arrival_date\n",
        "\n",
        "so remain :\n",
        "\n",
        "\n",
        "*   required_car_parking_space\n",
        "*   repeated_guest\n",
        "\n",
        "I will convert them to object and then put them back again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRMJhZ_kieCK"
      },
      "outputs": [],
      "source": [
        "discrete_features = [ \"arrival_year\" ,  \"arrival_month\" , \"arrival_date\" , \"required_car_parking_space\" , \"repeated_guest\" ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UujoLjXRency"
      },
      "outputs": [],
      "source": [
        "for col in discrete_features:\n",
        "    print(f\"{col} has {data[col].unique()} unique values\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3pJyv6njp08"
      },
      "source": [
        "\n",
        "\n",
        "*   Visualize Discrete Features with booking_status\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekMm5AcojyEi"
      },
      "outputs": [],
      "source": [
        "# Iterate through each feature and create plots\n",
        "for feature in discrete_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x=feature, hue='booking_status', data=data)\n",
        "    plt.title(f'{feature} vs booking_status')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend(title='booking_status', loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm5S45dvlGbl"
      },
      "source": [
        "I will analyze the rest of the continuous numerical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Wds_rTY5Ls"
      },
      "outputs": [],
      "source": [
        "continuous_features = []\n",
        "for col in data.columns:\n",
        "    if (data[col].dtype=='int64' or data[col].dtype=='float64') and col not in discrete_features:\n",
        "        continuous_features.append(col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkO7mF27Y5JT"
      },
      "outputs": [],
      "source": [
        "#printing the list\n",
        "print(f\"continuous variables :: \\n\\n{continuous_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-BIKogGl3DB"
      },
      "source": [
        "I'll have a look at the correlation between all the features with the help of Heatmap.                                                                   \n",
        "Heatmap will tell us which features are positively ,negatively and have no correlation with our target feature (booking_status)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EowNG3PfY5G9"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_corr = data[continuous_features]\n",
        "data_corr['booking_status'] = data['booking_status']\n",
        "\n",
        "corr = data_corr.corr()\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "#Here we use cmap CoolWarm as it gives us a better view of postive and negative correlation.\n",
        "#And with the help of vmin and vmax set to -1 and +1 , the features having values closer to +1 have positive correlation and features having values closer to -1 have negative correlation.\n",
        "sns.heatmap(corr,annot=True,linewidths=.5,cmap='coolwarm',vmin=-1,vmax=1,center=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXzHAk2xnJvf"
      },
      "source": [
        "Because Target is not a number, it does not appear in correlation, so I have to change it to the first number (label encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQp8sZ29Y5E7"
      },
      "outputs": [],
      "source": [
        "data.replace ({\"booking_status\" :{\"Canceled\" : 0 , \"Not_Canceled\" : 1}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8FBW3yuY5Cf"
      },
      "outputs": [],
      "source": [
        "data[\"booking_status\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-BQ5aNhnxiA"
      },
      "source": [
        "ooooops !!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ40G4X7Y5AK"
      },
      "outputs": [],
      "source": [
        "data = data.replace ({\"booking_status\" :{\"Canceled\" : 0 , \"Not_Canceled\" : 1}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17PfaYbPY49u"
      },
      "outputs": [],
      "source": [
        "data[\"booking_status\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLb8XjPNn5Z2"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_corr = data[continuous_features]\n",
        "data_corr['booking_status'] = data['booking_status']\n",
        "\n",
        "corr = data_corr.corr()\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "#Here we use cmap CoolWarm as it gives us a better view of postive and negative correlation.\n",
        "#And with the help of vmin and vmax set to -1 and +1 , the features having values closer to +1 have positive correlation and features having values closer to -1 have negative correlation.\n",
        "sns.heatmap(corr,annot=True,linewidths=.5,cmap='coolwarm',vmin=-1,vmax=1,center=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhyR2vQAoXKs"
      },
      "source": [
        "\n",
        "\n",
        "*   **positive correlation :**\n",
        "1.   no_of_special_requests\n",
        "2.   no_of_previous_bookings_not_canceled\n",
        "3.   no_of_previous_cancellations\n",
        "\n",
        "\n",
        "*   **negative correlation :**\n",
        "1.   no_of_adults\n",
        "2.   no_of_children\n",
        "3.   no_of_weekend_nights\n",
        "4.   no_of_week_nights\n",
        "5.   lead_time\n",
        "6.   avg_price_per_room\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LW7OIX-n5Un"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(rows=2, cols=2)\n",
        "\n",
        "# Add traces for each subplot\n",
        "fig.add_trace(go.Scatter(y=data['booking_status'], x=data['no_of_special_requests'], name='no_of_special_requests', mode='markers'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(y=data['booking_status'], x=data['no_of_previous_bookings_not_canceled'], name='no_of_previous_bookings_not_canceled', mode='markers'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(y=data['booking_status'], x=data['no_of_previous_cancellations'], name='no_of_previous_cancellations', mode='markers'), row=2, col=1)\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=1000, showlegend=True, title_text=\"Positive Correlated features with Sale Price\")\n",
        "\n",
        "# Show figure\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHFnPAxln5P_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA9mGiA_Y47s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAVTeGxkUjmA"
      },
      "outputs": [],
      "source": [
        "\n",
        "filtered_data = data[(data[\"no_of_children\"] > 0) & (data[\"no_of_adults\"] == 0 )]\n",
        "filtered_data[[\"no_of_children\" , \"no_of_adults\", \"booking_status\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRuQW1RpsNcP"
      },
      "source": [
        "as we see there is children with out adults !!                                  \n",
        "so i will remove these rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpcpo_PeWU-u"
      },
      "outputs": [],
      "source": [
        "rows_to_drop = data[(data[\"no_of_children\"] > 0) & (data[\"no_of_adults\"] == 0)].index\n",
        "data = data.drop(rows_to_drop)\n",
        "data = data.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MttIghGvWgCV"
      },
      "outputs": [],
      "source": [
        "data[(data[\"no_of_children\"] > 0) & (data[\"no_of_adults\"] == 0 )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-KmN02oW4EM"
      },
      "outputs": [],
      "source": [
        "filtered_data_ = data[(data[\"no_of_weekend_nights\"] == 0) & (data[\"no_of_week_nights\"] == 0 ) &(data[\"booking_status\"] == 1) ]\n",
        "filtered_data_[[\"no_of_weekend_nights\" , \"no_of_week_nights\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re5I3SV-uHLm"
      },
      "source": [
        "no_of_weekend_nights = 0  and no_of_week_nights and the booking not canceled !!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDY-A_izW4Az"
      },
      "outputs": [],
      "source": [
        "rows_to_drop = data[(data[\"no_of_weekend_nights\"] == 0) & (data[\"no_of_week_nights\"] == 0 )&(data[\"booking_status\"] == 1)].index\n",
        "data = data.drop(rows_to_drop)\n",
        "data = data.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ_hu5cJW12B"
      },
      "outputs": [],
      "source": [
        "data[(data[\"no_of_weekend_nights\"] == 0) & (data[\"no_of_week_nights\"] == 0 )&(data[\"booking_status\"] == 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2NHZ6vmYg1E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9UyzvSKudKv"
      },
      "source": [
        "# **Categorical Analysis**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFYtUbOCHImf"
      },
      "outputs": [],
      "source": [
        "categorical_features=[]\n",
        "for col in data.columns:\n",
        "    if data[col].dtype=='object':\n",
        "        categorical_features.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsq5lwNEukle"
      },
      "outputs": [],
      "source": [
        "#printing the list\n",
        "print(f\"Categorical variables :: \\n\\n{categorical_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4JuYsOeNJjk"
      },
      "outputs": [],
      "source": [
        "for i in categorical_features :\n",
        "  print (f\"{i} :: \\n{data[i].value_counts()}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ-bXqUvwli6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a count plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=data, x='type_of_meal_plan', hue='booking_status')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Type of Meal Plan')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Booking Status by Type of Meal Plan')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x52Q3cYfw5wq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a count plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=data, x='room_type_reserved', hue='booking_status')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Type of Meal Plan')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Booking Status by Type of room reserved')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcnVCjefxEWC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a count plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=data, x='market_segment_type', hue='booking_status')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Type of Meal Plan')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Booking Status by type of  market segment')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnbfE7nduqXq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfT6StOEx70z"
      },
      "source": [
        "# **Label encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYPLNrZONJhI"
      },
      "outputs": [],
      "source": [
        "data = data.replace({\"type_of_meal_plan\" : {\"Not Selected\" : 0, \"Meal Plan 1\" : 1 , \"Meal Plan 2\" : 2 , \"Meal Plan 3\" :3} ,\n",
        "                     \"room_type_reserved\" :  {\"Room_Type 1\" : 1 ,\"Room_Type 2\" : 2 , \"Room_Type 3\" : 3 , \"Room_Type 4\" : 4 , \"Room_Type 5\" : 5 , \"Room_Type 6\" : 6 , \"Room_Type 7\" : 7 },\n",
        "                     \"market_segment_type\" : {\"Offline\" : 1  , \"Online\" : 2 , \"Corporate\" : 3 ,\"Aviation\" : 4  , \"Complementary\" : 5 },\n",
        "                     #\"booking_status\" :{\"Canceled\" : 0 , \"Not_Canceled\" : 1}\n",
        "                     })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tuwAOE9Sfot"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zECL0Mo8NJeZ"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHlqfTHV0Wkr"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbwzZBZCzQK6"
      },
      "source": [
        "# **feature extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMLeg2XlzdSs"
      },
      "source": [
        "I can get the weather status from the arrival_month\n",
        "\n",
        "\n",
        "this data from Portugal so after searching :\n",
        "\n",
        "\n",
        "*   Summer (June to August)\n",
        "*   Fall (September to November)\n",
        "*   Winter (December to February)\n",
        "*   Spring (March to May)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4eHqSOQHdSi"
      },
      "outputs": [],
      "source": [
        "date_features = ['arrival_year','arrival_month','arrival_date']\n",
        "\n",
        "#printing the list\n",
        "print(f\"Categorical variables :: \\n\\n{date_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl1fQOFnKKFD"
      },
      "outputs": [],
      "source": [
        "for i in date_features :\n",
        "  print(f\"{i} ::\\n{data[i].value_counts()}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc7be3uASyG8"
      },
      "outputs": [],
      "source": [
        "# Summer (June to August)\n",
        "# Fall (September to November):\n",
        "# Winter (December to February)\n",
        "# Spring (March to May)\n",
        "\n",
        "\n",
        "\n",
        "def assign_temperature(month):\n",
        "    # Summer\n",
        "    if (month >=6 )& (month <=8):\n",
        "        return 1  # Average high in Lisbon for simplicity\n",
        "    # Fall\n",
        "    elif 9 <= month <= 11:\n",
        "        return 2  # Average high in September for simplicity\n",
        "    # Winter\n",
        "    elif month == 12 or 1 <= month <= 2:\n",
        "        return 3  # Average high in the north for simplicity\n",
        "    # Spring\n",
        "    elif 3 <= month <= 5:\n",
        "        return 4  # Average high for simplicity\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "data['temperature'] = data.apply(lambda x :assign_temperature(x[\"arrival_month\"]), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whn6L9LcbxZA"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6krNFwc072E"
      },
      "source": [
        "Total Number of Nights = (no_of_weekend_nights) + (no_of_week_nights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPMSRH500UMz"
      },
      "outputs": [],
      "source": [
        "def Total_Number_Nights (no_of_weekend_nights , no_of_week_nights):\n",
        "    return (no_of_weekend_nights + no_of_week_nights)\n",
        "\n",
        "data['Total_Number_Nights'] = data.apply(lambda x :Total_Number_Nights(x[\"no_of_weekend_nights\"] , x[\"no_of_week_nights\"]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQzatDLL0UJQ"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyUU3mQ-16f8"
      },
      "source": [
        "Total Guests = \t(no_of_adults) + (no_of_children)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yivh5VxC0UHJ"
      },
      "outputs": [],
      "source": [
        "def Total_Guests (no_of_adults , no_of_children):\n",
        "    return (no_of_adults + no_of_children)\n",
        "\n",
        "data['Total_Guests'] = data.apply(lambda x :Total_Number_Nights(x[\"no_of_adults\"] , x[\"no_of_children\"]), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI2lVfd50UFD"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIkACT-f-BOy"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsjef67N3o76"
      },
      "source": [
        "# **Separating target  and features variables from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0Aoi1PgcJEZ"
      },
      "outputs": [],
      "source": [
        "#Selecting features & target variable\n",
        "data_input = data.drop (columns='booking_status')\n",
        "data_output = data ['booking_status']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ackGkDob9h2f"
      },
      "source": [
        "# **Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfsNj9039ueE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXLzOkob9mLk"
      },
      "outputs": [],
      "source": [
        "selector = SelectKBest(f_classif, k=15)\n",
        "data_input = selector.fit_transform(data_input, data_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xzd3Mp99mIK"
      },
      "outputs": [],
      "source": [
        "selected_indices = selector.get_support(indices=True)\n",
        "# Get the names of the selected features\n",
        "selected_features = data.columns[selected_indices]\n",
        "\n",
        "# Print the names of the selected features\n",
        "print(\"Selected Features:\", selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwjxSlGp9mFg"
      },
      "outputs": [],
      "source": [
        "for i,j in enumerate(selector.scores_):\n",
        "    plt.bar(i,j)\n",
        "plt.xticks(range(data_input.shape[1]), selected_features , rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFN7xDM96VRe"
      },
      "source": [
        "# **Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4xF_DwU6n7K"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiOB2iCk6UjZ"
      },
      "outputs": [],
      "source": [
        "# Getting test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data_input,\n",
        "    data_output,\n",
        "    test_size=0.2,\n",
        "    random_state=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FItgHgxS6u7c"
      },
      "outputs": [],
      "source": [
        "print('Train size =', x_train.shape)\n",
        "print('Test size =', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0lx_HjT3yCz"
      },
      "source": [
        "# **Feature Scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycErZmnZ4Atk"
      },
      "source": [
        "*   There are two types of popular feature scaling methods :-\n",
        "1.   Standard Scaler\n",
        "2.   MinMax Scaler\n",
        "\n",
        "StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation. ... StandardScaler makes the mean of the distribution 0.             \n",
        "\n",
        "MinMaxScaler shrinks the range such that the range is now between 0 and 1.      \n",
        "\n",
        "We can use any one of them , in this exercise  I will go with StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqg6duMF5_43"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeuO6v_N34s5"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "#--------------------------------------------\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjDX3Cdn34pj"
      },
      "outputs": [],
      "source": [
        "x_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6Xgeso834nU"
      },
      "outputs": [],
      "source": [
        "x_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoNqSTER34i4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNlDdj9AAQoZ"
      },
      "source": [
        "# **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gsOKQwHjlss"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#--------------------------------------------------------\n",
        "from sklearn.metrics import accuracy_score\n",
        "#--------------------------------------------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#--------------------------------------------------------\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnpOu_uiC-oN"
      },
      "source": [
        "**helper functions to run models and Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVFL_sHceKk9"
      },
      "outputs": [],
      "source": [
        "def eval_classifier(model):\n",
        "    model.fit(x_train_scaled, y_train)\n",
        "    y_pred_train = model.predict(x_train_scaled)\n",
        "    y_pred_test  = model.predict(x_test_scaled)\n",
        "    acc_train    = accuracy_score(y_train, y_pred_train)\n",
        "    acc_test     = accuracy_score(y_test, y_pred_test)\n",
        "    print(model.__class__.__name__)\n",
        "    print(f\"acc train: {acc_train} and acc test : {acc_test}\\n\\n\")\n",
        "    print('----------------------------')\n",
        "    return acc_train , acc_test\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------\n",
        "def Grid_search (model , param_grid) :\n",
        "  try:\n",
        "    grid_search = GridSearchCV( estimator = model  , param_grid = param_grid, cv=5, scoring='accuracy', verbose=1 , n_jobs=-1 )\n",
        "    grid_search.fit(x_train_scaled, y_train)\n",
        "    best_model      = grid_search.best_estimator_\n",
        "    best_parameters = grid_search.best_params_\n",
        "    best_score      = grid_search.best_score_\n",
        "    # print(\"Best Parameters:\", best_parameters)\n",
        "    # print(\"Best Score:\", best_score)\n",
        "    y_pred_train = best_model.predict(x_train_scaled)\n",
        "    y_pred_test = best_model.predict(x_test_scaled)\n",
        "\n",
        "    acc_train = accuracy_score(y_train, y_pred_train)\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "    return best_model , best_parameters , best_score  , acc_train ,acc_test\n",
        "  except Exception as e:\n",
        "      print(\"Error during grid search:\", e)\n",
        "      return -1, -1, -1, -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWrcB4y3DOwD"
      },
      "source": [
        "# **Applying Decision Tree Classifier Model**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRWSWP3A8PUb",
        "outputId": "00f4f8d5-d623-482c-ca35-b3099d46485b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "acc train: 0.8323627287853578 and acc test : 0.8344425956738769\n",
            "\n",
            "\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini', splitter='best' ,max_depth=5, random_state=33)\n",
        "acc_train , acc_test= eval_classifier (DecisionTreeClassifierModel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXl2gTao8Wt-"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtU0MvEBejM0",
        "outputId": "3b39f0c8-6117-4d44-d80a-6affb99d3d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
            "best_model ::\n",
            "DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=33)\n",
            "\n",
            "best_parameters ::\n",
            "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "\n",
            "best_score :: 0.866472471492736\n",
            "\n",
            "acc train :: 0.8786051026067665\n",
            "\n",
            "acc_test :: 0.865363283416528\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_model , best_parameters , best_score , acc_train , acc_test = Grid_search (DecisionTreeClassifierModel , param_grid)\n",
        "print (f\"best_model ::\\n{best_model}\\n\\nbest_parameters ::\\n{best_parameters}\\n\\nbest_score :: {best_score}\\n\\nacc train :: {acc_train}\\n\\nacc_test :: {acc_test}\\n\\n \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvrJqLFmEC7H"
      },
      "source": [
        "# **Applying SVC Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "krDlBdx28nHV",
        "outputId": "10cd6827-3f52-4f5e-a8b0-187055f40f83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning:\n",
            "\n",
            "Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC\n",
            "acc train: 0.5970604547975596 and acc test : 0.5935940099833611\n",
            "\n",
            "\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "SVCModel = SVC( C = 1.0 ,\n",
        "               kernel = 'rbf',\n",
        "                degree = 4 ,\n",
        "                max_iter = 200 ,\n",
        "                gamma = 'auto',probability=True)\n",
        "\n",
        "\n",
        "\n",
        "acc_train , acc_test = eval_classifier (SVCModel)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pbO5g4SWk-vU"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1,2,3, 10],              # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],    # Kernel type\n",
        "    'max_iter': [100 , 200 , 300 , 400 , 500],        # Maximum number of iterations\n",
        "    'gamma': ['scale', 'auto'],     # Kernel coefficient\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNAtnMlxmQD6",
        "outputId": "f1881a93-daa1-4a8f-dada-34ed287e73e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning:\n",
            "\n",
            "Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model ::\n",
            "SVC(C=0.1, degree=4, kernel='linear', max_iter=300, probability=True)\n",
            "\n",
            "best_parameters ::\n",
            "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 300}\n",
            "\n",
            "best_score ::0.6963070051398244\n",
            "\n",
            "acc_test ::0.6548807542983915\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_model , best_parameters , best_score , acc_train , acc_test = Grid_search (SVCModel , param_grid)\n",
        "\n",
        "print (f\"best_model ::\\n{best_model}\\n\\nbest_parameters ::\\n{best_parameters}\\n\\nbest_score ::{best_score}\\n\\nacc_test ::{acc_test}\\n\\n \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbndMpBK9Bhe"
      },
      "source": [
        "# **Applying KNeighborsClassifier Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NEqpBlRX9PfT",
        "outputId": "c75b9560-c34d-48b1-9d07-a8caf064efd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier\n",
            "acc train: 0.8982945091514143 and acc test : 0.8545479755962285\n",
            "\n",
            "\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "KNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='uniform', algorithm='auto')\n",
        "acc_train , acc_test = eval_classifier (KNNClassifierModel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3UHVnnhJmXMW"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7],       # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm used to compute nearest neighbors\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx9zBE_HmqN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d4c388-5980-49de-85f2-db3fde422bd0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_model , best_parameters , best_score , acc_train ,acc_test = Grid_search (KNNClassifierModel , param_grid)\n",
        "print (f\"best_model ::\\n{best_model}\\n\\nbest_parameters ::\\n{best_parameters}\\n\\nbest_score :: {best_score}\\n\\nacc train :: {acc_train}\\n\\nacc_test :: {acc_test}\\n\\n \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpNeYJn-9VM4"
      },
      "source": [
        "#**Applying RandomForestClassifier Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fSiDTr_9lJu"
      },
      "outputs": [],
      "source": [
        "\n",
        "RandomForestClassifierModel = RandomForestClassifier(criterion = 'gini',n_estimators=100,max_depth=8, min_samples_split = 2 , random_state = 33 ) #criterion can be also : entropy\n",
        "acc_train , acc_test = eval_classifier (RandomForestClassifierModel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLIRD1GinmVm"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150 , 200],      # Number of trees in the forest\n",
        "    'criterion': ['gini', 'entropy'],    # Criterion for split\n",
        "    'max_depth': [2, 3, 4, 5,6,7,8,9],               # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 3, 4,5,6],       # Minimum number of samples required to split a node\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJJ1wB0znmSO"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_model , best_parameters , best_score , acc_train , acc_test = Grid_search (RandomForestClassifierModel , param_grid)\n",
        "print (f\"best_model ::\\n{best_model}\\n\\nbest_parameters ::\\n{best_parameters}\\n\\nbest_score :: {best_score}\\n\\nacc train :: {acc_train}\\n\\nacc_test :: {acc_test}\\n\\n \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prMkc04R9vA9"
      },
      "source": [
        "# **Applying LogisticRegression Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OY3v7e896uG"
      },
      "outputs": [],
      "source": [
        "\n",
        "LogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag',C=1.0,random_state=33)\n",
        "acc_train , acc_test = eval_classifier (LogisticRegressionModel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_dKj7QmiQuc"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92QOJRlti0Zp"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_model , best_parameters , best_score , acc_train , acc_test = Grid_search (LogisticRegressionModel , param_grid)\n",
        "print (f\"best_model ::\\n{best_model}\\n\\nbest_parameters ::\\n{best_parameters}\\n\\nbest_score :: {best_score}\\n\\nacc train :: {acc_train}\\n\\nacc_test :: {acc_test}\\n\\n \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyGdY87Ji2qa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvVh6PXqnmNo"
      },
      "outputs": [],
      "source": [
        "#DecisionTreeClassifier , SVC , KNeighborsClassifier , RandomForestClassifier , LogisticRegressionModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amPNl4Vi9__H"
      },
      "source": [
        "# **Applying VotingClassifier Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "jmDfIoXdnjo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe969511-f28c-4d1b-9c12-b5c814eba935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning:\n",
            "\n",
            "Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingClassifier\n",
            "acc train: 0.8536120354963949 and acc test : 0.8451192457016085\n",
            "\n",
            "\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "VotingClassifierModel = VotingClassifier(estimators=[( 'DecisionTreeClassifier'  , DecisionTreeClassifierModel  ) ,\n",
        "                                                     ( 'RandomForestClassifier'  , RandomForestClassifierModel   ) ,\n",
        "                                                     ( 'LogisticRegressionModel' , LogisticRegressionModel  ) ,\n",
        "                                                     ( 'SVCModel'                , SVCModel                      ) ,\n",
        "                                                     ( 'KNNModel'                , KNNClassifierModel     )],\n",
        "                                                       voting = 'hard' )\n",
        "\n",
        "\n",
        "acc_train , acc_test = eval_classifier (VotingClassifierModel)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "0biNtDr3MSsG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "q9UyzvSKudKv",
        "QfT6StOEx70z",
        "ZbwzZBZCzQK6",
        "gsjef67N3o76",
        "ackGkDob9h2f",
        "TFN7xDM96VRe",
        "V0lx_HjT3yCz",
        "dNlDdj9AAQoZ",
        "pWrcB4y3DOwD",
        "SvrJqLFmEC7H",
        "bbndMpBK9Bhe",
        "JpNeYJn-9VM4",
        "prMkc04R9vA9"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPJu2bTTiXD4aBeVS8Gq+eB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}